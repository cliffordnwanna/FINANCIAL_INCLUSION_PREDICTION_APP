# -*- coding: utf-8 -*-
"""train_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mFTiHspwta-KolurAjurm6FG_WIk99lc
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import pickle
import gdown
import os

# Function to create directories if they do not exist
def create_directory(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)

# Function to download dataset from Google Drive
def download_dataset_from_gdrive(gdrive_url, output_path):
    # Ensure the directory for the output file exists
    create_directory(os.path.dirname(output_path))

    if not os.path.exists(output_path):
        print("Downloading dataset from Google Drive...")
        gdown.download(gdrive_url, output_path, quiet=False)
        print("Download complete!")
    else:
        print("Dataset already exists. Skipping download.")

# Google Drive URL (replace with your actual file ID)
gdrive_url = "https://drive.google.com/uc?id=1FrFTfUln67599LTm2uMTSqM8DjqpAaKL"  # Replace with your actual file ID
dataset_path = "data/Financial_inclusion_dataset.csv"

# Download dataset
download_dataset_from_gdrive(gdrive_url, dataset_path)

# Load dataset
df = pd.read_csv(dataset_path)

# Data preprocessing
def preprocess_data(df):
    df_filled = df.fillna(0)
    categorical_columns = ['country', 'year', 'uniqueid', 'location_type',
                           'cellphone_access', 'household_size', 'age_of_respondent',
                           'gender_of_respondent', 'relationship_with_head',
                           'marital_status', 'education_level', 'job_type']

    label_encoder = LabelEncoder()
    for col in categorical_columns:
        df_filled[col] = df_filled[col].astype(str)
        df_filled[col] = label_encoder.fit_transform(df_filled[col])

    return df_filled

# Train model
def train_model():
    # Create models directory if it doesn't exist
    create_directory("models")

    df_cleaned = preprocess_data(df)
    X = df_cleaned.drop('bank_account', axis=1)  # Change 'bank_account' to your target variable if different
    y = df_cleaned['bank_account']  # Change 'bank_account' to your target variable if different

    # Split dataset
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train classifier
    clf = RandomForestClassifier()
    clf.fit(X_train, y_train)

    # Test accuracy
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print("Model Accuracy:", accuracy)

    # Save model
    with open("models/streamlit_trained_model.sav", 'wb') as f:
        pickle.dump(clf, f)

if __name__ == "__main__":
    train_model()

